{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from -r requirement.txt (line 1)) (1.0.1)\n",
      "Requirement already satisfied: langchain in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from -r requirement.txt (line 2)) (0.3.9)\n",
      "Requirement already satisfied: langchain_core in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from -r requirement.txt (line 3)) (0.3.21)\n",
      "Requirement already satisfied: langchain_community in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from -r requirement.txt (line 4)) (0.3.9)\n",
      "Requirement already satisfied: langchain-ollama in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from -r requirement.txt (line 5)) (0.2.1)\n",
      "Requirement already satisfied: langchain_text_splitters in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from -r requirement.txt (line 6)) (0.3.2)\n",
      "Requirement already satisfied: langchain-huggingface in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from -r requirement.txt (line 7)) (0.1.2)\n",
      "Requirement already satisfied: faiss-cpu in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from -r requirement.txt (line 8)) (1.9.0.post1)\n",
      "Requirement already satisfied: chromadb in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from -r requirement.txt (line 10)) (0.5.23)\n",
      "Requirement already satisfied: sentence-transformers in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from -r requirement.txt (line 11)) (3.3.1)\n",
      "Requirement already satisfied: tiktoken in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from -r requirement.txt (line 12)) (0.8.0)\n",
      "Requirement already satisfied: pypdf in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from -r requirement.txt (line 13)) (5.1.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from langchain->-r requirement.txt (line 2)) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from langchain->-r requirement.txt (line 2)) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from langchain->-r requirement.txt (line 2)) (3.11.10)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from langchain->-r requirement.txt (line 2)) (0.1.147)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from langchain->-r requirement.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from langchain->-r requirement.txt (line 2)) (2.10.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from langchain->-r requirement.txt (line 2)) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from langchain->-r requirement.txt (line 2)) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from langchain_core->-r requirement.txt (line 3)) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from langchain_core->-r requirement.txt (line 3)) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from langchain_core->-r requirement.txt (line 3)) (4.12.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from langchain_community->-r requirement.txt (line 4)) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from langchain_community->-r requirement.txt (line 4)) (0.4.0)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from langchain_community->-r requirement.txt (line 4)) (2.6.1)\n",
      "Requirement already satisfied: ollama<1,>=0.3.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from langchain-ollama->-r requirement.txt (line 5)) (0.4.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from langchain-huggingface->-r requirement.txt (line 7)) (0.26.5)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from langchain-huggingface->-r requirement.txt (line 7)) (0.20.3)\n",
      "Requirement already satisfied: transformers>=4.39.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from langchain-huggingface->-r requirement.txt (line 7)) (4.46.3)\n",
      "Requirement already satisfied: build>=1.0.3 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from chromadb->-r requirement.txt (line 10)) (1.2.2.post1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from chromadb->-r requirement.txt (line 10)) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from chromadb->-r requirement.txt (line 10)) (0.115.6)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirement.txt (line 10)) (0.32.1)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from chromadb->-r requirement.txt (line 10)) (3.7.4)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from chromadb->-r requirement.txt (line 10)) (1.20.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from chromadb->-r requirement.txt (line 10)) (1.28.2)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from chromadb->-r requirement.txt (line 10)) (1.28.2)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from chromadb->-r requirement.txt (line 10)) (0.49b2)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from chromadb->-r requirement.txt (line 10)) (1.28.2)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from chromadb->-r requirement.txt (line 10)) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from chromadb->-r requirement.txt (line 10)) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from chromadb->-r requirement.txt (line 10)) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from chromadb->-r requirement.txt (line 10)) (6.4.5)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from chromadb->-r requirement.txt (line 10)) (1.68.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from chromadb->-r requirement.txt (line 10)) (4.2.1)\n",
      "Requirement already satisfied: typer>=0.9.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from chromadb->-r requirement.txt (line 10)) (0.15.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from chromadb->-r requirement.txt (line 10)) (31.0.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from chromadb->-r requirement.txt (line 10)) (5.0.1)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from chromadb->-r requirement.txt (line 10)) (3.10.12)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from chromadb->-r requirement.txt (line 10)) (0.27.2)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from chromadb->-r requirement.txt (line 10)) (13.9.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from sentence-transformers->-r requirement.txt (line 11)) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from sentence-transformers->-r requirement.txt (line 11)) (1.5.2)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from sentence-transformers->-r requirement.txt (line 11)) (1.14.1)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from sentence-transformers->-r requirement.txt (line 11)) (11.0.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from tiktoken->-r requirement.txt (line 12)) (2024.11.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirement.txt (line 2)) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirement.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirement.txt (line 2)) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirement.txt (line 2)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirement.txt (line 2)) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirement.txt (line 2)) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirement.txt (line 2)) (1.18.3)\n",
      "Requirement already satisfied: pyproject_hooks in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from build>=1.0.3->chromadb->-r requirement.txt (line 10)) (1.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community->-r requirement.txt (line 4)) (3.23.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community->-r requirement.txt (line 4)) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb->-r requirement.txt (line 10)) (0.41.3)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb->-r requirement.txt (line 10)) (4.7.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb->-r requirement.txt (line 10)) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb->-r requirement.txt (line 10)) (1.0.7)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb->-r requirement.txt (line 10)) (3.10)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb->-r requirement.txt (line 10)) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb->-r requirement.txt (line 10)) (0.14.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface->-r requirement.txt (line 7)) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface->-r requirement.txt (line 7)) (2024.10.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain_core->-r requirement.txt (line 3)) (3.0.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb->-r requirement.txt (line 10)) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb->-r requirement.txt (line 10)) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb->-r requirement.txt (line 10)) (2.36.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb->-r requirement.txt (line 10)) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb->-r requirement.txt (line 10)) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb->-r requirement.txt (line 10)) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb->-r requirement.txt (line 10)) (2.2.3)\n",
      "Requirement already satisfied: durationpy>=0.7 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb->-r requirement.txt (line 10)) (0.9)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain->-r requirement.txt (line 2)) (1.0.0)\n",
      "Requirement already satisfied: coloredlogs in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb->-r requirement.txt (line 10)) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb->-r requirement.txt (line 10)) (24.3.25)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb->-r requirement.txt (line 10)) (5.29.1)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb->-r requirement.txt (line 10)) (1.13.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb->-r requirement.txt (line 10)) (1.2.15)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb->-r requirement.txt (line 10)) (8.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirement.txt (line 10)) (1.66.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.28.2 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirement.txt (line 10)) (1.28.2)\n",
      "Requirement already satisfied: opentelemetry-proto==1.28.2 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirement.txt (line 10)) (1.28.2)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.49b2 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirement.txt (line 10)) (0.49b2)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.49b2 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirement.txt (line 10)) (0.49b2)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirement.txt (line 10)) (0.49b2)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.49b2 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirement.txt (line 10)) (0.49b2)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirement.txt (line 10)) (1.17.0)\n",
      "Requirement already satisfied: asgiref~=3.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from opentelemetry-instrumentation-asgi==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirement.txt (line 10)) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb->-r requirement.txt (line 10)) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb->-r requirement.txt (line 10)) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requirement.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requirement.txt (line 2)) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from requests<3,>=2->langchain->-r requirement.txt (line 2)) (3.4.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from rich>=10.11.0->chromadb->-r requirement.txt (line 10)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from rich>=10.11.0->chromadb->-r requirement.txt (line 10)) (2.18.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers->-r requirement.txt (line 11)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers->-r requirement.txt (line 11)) (3.1.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from sympy->onnxruntime>=1.14.1->chromadb->-r requirement.txt (line 10)) (1.3.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from transformers>=4.39.0->langchain-huggingface->-r requirement.txt (line 7)) (0.4.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from typer>=0.9.0->chromadb->-r requirement.txt (line 10)) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from typer>=0.9.0->chromadb->-r requirement.txt (line 10)) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirement.txt (line 10)) (0.6.4)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirement.txt (line 10)) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirement.txt (line 10)) (1.0.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirement.txt (line 10)) (14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from scikit-learn->sentence-transformers->-r requirement.txt (line 11)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from scikit-learn->sentence-transformers->-r requirement.txt (line 11)) (3.5.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirement.txt (line 10)) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirement.txt (line 10)) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirement.txt (line 10)) (4.9)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb->-r requirement.txt (line 10)) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb->-r requirement.txt (line 10)) (0.1.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community->-r requirement.txt (line 4)) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb->-r requirement.txt (line 10)) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers->-r requirement.txt (line 11)) (3.0.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirement.txt (line 10)) (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirement.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# If you want to load all PDFs from a directory:\n",
    "directory_path = \"docs/\"\n",
    "pdf_files = [os.path.join(directory_path, file) for file in os.listdir(directory_path) if file.endswith(\".pdf\")]\n",
    "\n",
    "# Load documents from multiple PDFs\n",
    "documents = []\n",
    "for pdf_file in pdf_files:\n",
    "    loader = PyPDFLoader(pdf_file)\n",
    "    documents.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Split the documents into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = text_splitter.split_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chroma database created with 68 chunks!\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# Initialize embeddings model (using SentenceTransformers)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create Chroma database\n",
    "vectorstore = Chroma.from_documents(chunks, embeddings, persist_directory=\"./chroma_store\")\n",
    "print(f\"Chroma database created with {len(chunks)} chunks!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM  # Correct import\n",
    "\n",
    "# Initialize the Ollama LLM\n",
    "llm = OllamaLLM(model=\"llama3\", base_url=\"http://127.0.0.1:11434\")  # Replace with your model and base URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/basic-rag/lib/python3.11/site-packages/langsmith/client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=005d6a84-7335-47e4-9b79-8c0d33ddcfe9,id=005d6a84-7335-47e4-9b79-8c0d33ddcfe9; trace=b4094e62-1f45-4cf4-bf37-350a0612faae,id=b4094e62-1f45-4cf4-bf37-350a0612faae\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: According to the context, Chunking refers to the process of breaking down large documents or text data into smaller, manageable pieces (or chunks). Each chunk is designed to be semantically coherent and easily retrievable.\n",
      "Source Documents: [{'page': 0, 'source': 'docs/RAG_Chunking_Tutorial.pdf'}, {'page': 13, 'source': 'docs/rag_chunking_example.pdf'}, {'page': 4, 'source': 'docs/rag_chunking_example.pdf'}, {'page': 10, 'source': 'docs/rag_chunking_example.pdf'}]\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "query = \"What is chunking?\"\n",
    "\n",
    "# Retrieve top-k documents using the invoke method\n",
    "retrieved_docs = retriever.invoke(query)  # Modify this to use the invoke method\n",
    "top_k = 5  # Set the number of top documents you want to retrieve\n",
    "\n",
    "# Ensure that the retrieved_docs is a list and slice to top_k\n",
    "if isinstance(retrieved_docs, dict):\n",
    "    retrieved_docs = retrieved_docs.get('documents', [])\n",
    "\n",
    "retrieved_docs = retrieved_docs[:top_k]  # Retrieve only the top-k documents\n",
    "\n",
    "# Combine the content of the documents into a single context\n",
    "context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "# Feed the combined context to the LLM\n",
    "prompt = f\"Context:\\n{context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "\n",
    "# Generate the response using Ollama\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "# Print the response and the source documents\n",
    "print(\"Answer:\", response)\n",
    "print(\"Source Documents:\", [doc.metadata for doc in retrieved_docs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=33e0d8b2-b5ca-4ecf-b3d0-6008c287ff9b,id=33e0d8b2-b5ca-4ecf-b3d0-6008c287ff9b; trace=b4094e62-1f45-4cf4-bf37-350a0612faae,id=b4094e62-1f45-4cf4-bf37-350a0612faae\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=aa845c02-b946-4c6a-a248-4bb8ae578bdc,id=aa845c02-b946-4c6a-a248-4bb8ae578bdc; trace=33e0d8b2-b5ca-4ecf-b3d0-6008c287ff9b,id=33e0d8b2-b5ca-4ecf-b3d0-6008c287ff9b\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=aa86486f-2fbc-42f5-8ba2-08dbba44c128,id=aa86486f-2fbc-42f5-8ba2-08dbba44c128; trace=aa845c02-b946-4c6a-a248-4bb8ae578bdc,id=aa845c02-b946-4c6a-a248-4bb8ae578bdc\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=fdb0cf12-e64e-4078-9c58-a2923c449269,id=fdb0cf12-e64e-4078-9c58-a2923c449269; trace=aa86486f-2fbc-42f5-8ba2-08dbba44c128,id=aa86486f-2fbc-42f5-8ba2-08dbba44c128\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=3efd2f44-654b-4319-863b-0e5552a3a0bd,id=3efd2f44-654b-4319-863b-0e5552a3a0bd; trace=fdb0cf12-e64e-4078-9c58-a2923c449269,id=fdb0cf12-e64e-4078-9c58-a2923c449269\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=00279713-3f22-45e9-b947-6f56db392302,id=00279713-3f22-45e9-b947-6f56db392302; trace=3efd2f44-654b-4319-863b-0e5552a3a0bd,id=3efd2f44-654b-4319-863b-0e5552a3a0bd\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=be8689bc-9484-4b5b-9b7c-84d768799b92,id=be8689bc-9484-4b5b-9b7c-84d768799b92; trace=00279713-3f22-45e9-b947-6f56db392302,id=00279713-3f22-45e9-b947-6f56db392302\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=33f2a4de-42e3-480c-bfb6-8ff8846a8ef8,id=33f2a4de-42e3-480c-bfb6-8ff8846a8ef8; trace=be8689bc-9484-4b5b-9b7c-84d768799b92,id=be8689bc-9484-4b5b-9b7c-84d768799b92\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=33f2a4de-42e3-480c-bfb6-8ff8846a8ef8,id=33f2a4de-42e3-480c-bfb6-8ff8846a8ef8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: According to the provided context, effective chunking ensures that:\n",
      "\n",
      "* The text is divided into sections that are neither too long nor too short.\n",
      "* This helps optimize both retrieval and learning processes.\n",
      "\n",
      "In other words, the advantages of using chunking include:\n",
      "\n",
      "* Optimized retrieval: Chunking allows for efficient retrieval of specific information from large documents or datasets.\n",
      "* Optimized learning: By dividing text into manageable pieces (chunks), learners can focus on specific sections of content, making it easier to learn and retain new information.\n",
      "Source Documents: [{'page': 9, 'source': 'docs/rag_chunking_example.pdf'}, {'page': 3, 'source': 'docs/rag_chunking_example.pdf'}, {'page': 0, 'source': 'docs/RAG_Chunking_Tutorial.pdf'}, {'page': 4, 'source': 'docs/rag_chunking_example.pdf'}]\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "query = \"What is the advantages or effect when using chunking?\"\n",
    "\n",
    "# Retrieve top-k documents using the invoke method\n",
    "retrieved_docs = retriever.invoke(query)  # Modify this to use the invoke method\n",
    "top_k = 5  # Set the number of top documents you want to retrieve\n",
    "\n",
    "# Ensure that the retrieved_docs is a list and slice to top_k\n",
    "if isinstance(retrieved_docs, dict):\n",
    "    retrieved_docs = retrieved_docs.get('documents', [])\n",
    "\n",
    "retrieved_docs = retrieved_docs[:top_k]  # Retrieve only the top-k documents\n",
    "\n",
    "# Combine the content of the documents into a single context\n",
    "context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "# Feed the combined context to the LLM\n",
    "prompt = f\"Context:\\n{context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "\n",
    "# Generate the response using Ollama\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "# Print the response and the source documents\n",
    "print(\"Answer:\", response)\n",
    "print(\"Source Documents:\", [doc.metadata for doc in retrieved_docs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Retrieval-Augmented Generation (RAG) is a framework that combines pre-trained language models with external knowledge bases to enhance the accuracy and relevance of generated text.\n",
      "Source Documents: [{'page': 4, 'source': 'docs/rag_chunking_example.pdf'}, {'page': 10, 'source': 'docs/rag_chunking_example.pdf'}, {'page': 0, 'source': 'docs/RAG_Chunking_Tutorial.pdf'}, {'page': 1, 'source': 'docs/RAG_Chunking_Tutorial.pdf'}]\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "query = \"What is RAG?\"\n",
    "\n",
    "# Retrieve top-k documents using the invoke method\n",
    "retrieved_docs = retriever.invoke(query)  # Modify this to use the invoke method\n",
    "top_k = 5  # Set the number of top documents you want to retrieve\n",
    "\n",
    "# Ensure that the retrieved_docs is a list and slice to top_k\n",
    "if isinstance(retrieved_docs, dict):\n",
    "    retrieved_docs = retrieved_docs.get('documents', [])\n",
    "\n",
    "retrieved_docs = retrieved_docs[:top_k]  # Retrieve only the top-k documents\n",
    "\n",
    "# Combine the content of the documents into a single context\n",
    "context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "# Feed the combined context to the LLM\n",
    "prompt = f\"Context:\\n{context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "\n",
    "# Generate the response using Ollama\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "# Print the response and the source documents\n",
    "print(\"Answer:\", response)\n",
    "print(\"Source Documents:\", [doc.metadata for doc in retrieved_docs])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Including Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Based on the provided context, I'd be happy to help!\n",
      "\n",
      "RAG stands for Retrieval-Augmented Generation. It's a framework that combines pre-trained language models with external knowledge bases to enhance the accuracy and relevance of generated text. In other words, instead of relying solely on the model's internal knowledge, RAG retrieves relevant chunks of information from external sources, such as document collections, to assist in generation.\n",
      "\n",
      "To put it simply, RAG is a way to improve the quality of AI-generated text by bringing in additional information and insights from outside sources. This allows for more accurate and relevant responses to user queries.\n",
      "\n",
      "I hope that helps clarify things! Let me know if you have any further questions or if there's anything else I can help with.\n",
      "Source Documents: [{'page': 4, 'source': 'docs/rag_chunking_example.pdf'}, {'page': 10, 'source': 'docs/rag_chunking_example.pdf'}, {'page': 0, 'source': 'docs/RAG_Chunking_Tutorial.pdf'}, {'page': 1, 'source': 'docs/RAG_Chunking_Tutorial.pdf'}]\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "query = \"What is RAG?\"\n",
    "\n",
    "# Retrieve top-k documents using the invoke method\n",
    "retrieved_docs = retriever.invoke(query)  # Modify this to use the invoke method\n",
    "top_k = 5  # Set the number of top documents you want to retrieve\n",
    "\n",
    "# Ensure that the retrieved_docs is a list and slice to top_k\n",
    "if isinstance(retrieved_docs, dict):\n",
    "    retrieved_docs = retrieved_docs.get('documents', [])\n",
    "\n",
    "retrieved_docs = retrieved_docs[:top_k]  # Retrieve only the top-k documents\n",
    "\n",
    "# Combine the content of the documents into a single context\n",
    "context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "# Feed the combined context to the LLM\n",
    "prompt = f\"\"\"\n",
    "You are an expert AI assistant. Use the provided context to answer the question in a clear, concise, and professional manner. \n",
    "If the context is insufficient, respond with \"The context provided does not contain enough information to answer this question.\"\n",
    "\n",
    "### Context:\n",
    "{context}\n",
    "\n",
    "### Instructions:\n",
    "1. Summarize key details from the context where relevant.\n",
    "2. Answer the question in a way that is easy to understand for a general audience.\n",
    "3. Where applicable, provide examples or additional clarifications to make the response more insightful.\n",
    "\n",
    "### Question:\n",
    "{query}\n",
    "\n",
    "### Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Generate the response using Ollama\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "# Print the response and the source documents\n",
    "print(\"Answer:\", response)\n",
    "print(\"Source Documents:\", [doc.metadata for doc in retrieved_docs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Based on the provided context, RAG (Retrieval-Augmented Generation) is a framework that combines pre-trained language models with external knowledge bases to enhance the accuracy and relevance of generated text. This framework retrieves relevant chunks of information from external sources, such as document collections, to assist in generation.\n",
      "\n",
      "Sources: Context provided\n",
      "\n",
      "Note: No additional information was required beyond what was provided in the context.\n",
      "Source Documents:\n",
      "- Page Content: RAG Chunking Example Document\n",
      "accuracy and processing speed. This document is structured to facilitate experimentation with\n",
      "various chunking techniques, including overlapping windows, recursive splitt...\n",
      "  Metadata: {'page': 4, 'source': 'docs/rag_chunking_example.pdf'}\n",
      "- Page Content: RAG Chunking Example Document\n",
      "accuracy and processing speed. This document is structured to facilitate experimentation with\n",
      "various chunking techniques, including overlapping windows, recursive splitt...\n",
      "  Metadata: {'page': 10, 'source': 'docs/rag_chunking_example.pdf'}\n",
      "- Page Content: Understanding Retrieval-Augmented Generation (RAG) with Chunking\n",
      "1. Introduction to Retrieval-Augmented Generation (RAG)\n",
      "Retrieval-Augmented Generation (RAG) is a framework that combines pre-trained l...\n",
      "  Metadata: {'page': 0, 'source': 'docs/RAG_Chunking_Tutorial.pdf'}\n",
      "- Page Content: Step 4: Retrieving Chunks for RAG\n",
      "When a query is made, retrieve the most relevant chunks from the database using vector search.\n",
      "These chunks are then fed into the language model to generate responses...\n",
      "  Metadata: {'page': 1, 'source': 'docs/RAG_Chunking_Tutorial.pdf'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "query = \"What is RAG?\"\n",
    "\n",
    "# Retrieve top-k documents using the invoke method\n",
    "retrieved_docs = retriever.invoke(query)  # Modify this to use the invoke method\n",
    "top_k = 5  # Set the number of top documents you want to retrieve\n",
    "\n",
    "# Ensure that the retrieved_docs is a list and slice to top_k\n",
    "if isinstance(retrieved_docs, dict):\n",
    "    retrieved_docs = retrieved_docs.get('documents', [])\n",
    "\n",
    "retrieved_docs = retrieved_docs[:top_k]  # Retrieve only the top-k documents\n",
    "\n",
    "# Combine the content of the documents into a single context\n",
    "context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "# Advanced prompt with retrieval and Llama 3's knowledge\n",
    "prompt = f\"\"\"\n",
    "You are an expert AI assistant. Use the provided context and your own knowledge to answer the question in a clear, concise, and professional manner. \n",
    "\n",
    "### Instructions:\n",
    "1. First, prioritize using the context to provide the answer.\n",
    "2. If additional information is needed, supplement your response with your own knowledge.\n",
    "3. Always provide the sources for any information retrieved from the context.\n",
    "4. If the context does not answer the question and you rely solely on your own knowledge, clearly state that no external sources were used.\n",
    "\n",
    "### Context:\n",
    "{context}\n",
    "\n",
    "### Question:\n",
    "{query}\n",
    "\n",
    "### Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Generate the response using Ollama\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "# Print response and source information\n",
    "print(\"Answer:\", response)\n",
    "print(\"Source Documents:\")\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"- Page Content: {doc.page_content[:200]}...\")  # Truncated for readability\n",
    "    print(f\"  Metadata: {doc.metadata}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
